
Fault Tolerance Service (FTS)
================================

This document illustrates the mechanism of a GPDB component called Fault
Tolerance Service (FTS):

1. The FTS probe process is running on the Gp_entry_postmaster (master
   node) only. It is started by ServerLoop() of postmaster. There we start
   a group of GP background processes through a structure PMSubProcList.
   PMSubProcList is an array and each entry contains the description of a
   GP background process, including the main entry function of the process
   and a flag to indicate on what type (master, segment, or both) of nodes
   this process can be started. The first entry in the array is about the
   FTS probe. When its flag is checked, it says only  Gp_entry_postmaster
   can start it.

   PR 7364 has made some changes to the above implementation recently and
   merged its code in July 2019. It no longer starts FTS probe process as
   a dedicated auxiliary process. Instead, it is started as a background
   worker process managed by the BackgroundWorker structure. (see
   src/include/postmaster/bgworker.h). The PMSubProcList is still in use
   but its definition has been changed to: 

         #define MaxPMAuxProc 6 
         static BackgroundWorker PMAuxProcList[MaxPMAuxProc]  

   The most important members of the BackgroundWorker structure are two
   function pointers. One is the pointer of the main entry function of the
   GP background process and the other one is the pointer of the function
   that determine if the process should be started. For FTS, the two
   pointers are FtsProbeMain() and FtsProbeStartRule(), respectively.

     Now in Postmaster, we will check the following condition:

        Gp_entry_postmaster && Gp_role == GP_ROLE_DISPATCH

   and start the FTS probe process only when the condition is true. All
   these are done in load_auxiliary_libraries() which now is responsible
   for starting all GP background processes.

   Note: load_auxiliary_libraries() is called outside of ServerLoop().
         Not sure about the implication of this difference.

2. The FTS probe process usually runs in a infinite loop. A few things
   could trigger a round of polling to get the health status of all
   segment nodes:

    - First, the main loop of FTS process does the polling once for each
      iteration. This might be too frequent, so FTS adds a sleep() call
      in each iteration. This can reduce the number of polling.

    - Second, FTS allows some events to trigger the polling. It registers
      a callback function for four types of events: deadlock timeout,
      statement timeout, lock timeout, and gang timeout. The callback
      simply signals postmaster with SIGINT, and the postmaster’s SIGINT
      handler will set a global variable "probe_requested" to true. In the
      main loop of FTS probe, we check this variable before we call sleep().
      As a result, the sleep can be skipped and it looks like FTS does a
      urgent polling. In general, it makes sense because these events
      often occur when some segment node is down.

    - Third, also the last, in some code running on the master node, such as
      the function cdbgang_createGang_async(), if we unfortunately hit the
      PG_CATCH block, we will also trigger the SIGINT signal by calling a
      function FtsNotifyProber(). Then the master node does the same thing
      for the signal just like what it does in the second case.

    PR 7364 has also made some changes to this part. We no longer registers
    callback to the above four types of timeout events. Now we solely
    rely on the FtsNotifyProber() function to send SIGINT signal to
    postmaster when we hit the PG_CATCH block somewhere in the code running
    on master node.

    Note: Not sure about the changes of PR 7364 covers the cases of
          timeout event. Or there is no need to care about them
          because they have been handled in other ways.

3. On the master node side, the FTS probe process gets the configuration
   from catelog table pg_segement_configure, which describes the status of
   each segment and also tells if any of them has a mirror. In a simple
   case, we can think of that, for each unique content(or segindex) value,
   we may see a primary segment and a mirror segment. The two make a pair
   and they have the same content(or segindex) value but different dbid.
   The FTS’s job is to periodically (sometimes event driven) poll all the
   segments that have mirror setup. If any of them is in down status, FTS
   promotes the mirror to be the primary (swap them). In summary, The FTS
   probe gets the needed information of all segments from these catalog
   tables and also update them according to the dynamically changing
   runtime status.

4. On the master node side: each round of the polling is done in a chain of
   calls :

        ftsConnect()
        ftsPoll()
        ftsSend()
        ftsReceive()
        processRetry()
        processResponse().

   FTS probe process connects to each primary segment node(or mirror segment
   when failover occurs) through TCP/IP. It sends requests to segment and
   waits for the responses. Once a response is received, it updates the
   catalog table pg_segement_configure and pg_configure_history, and also
   relevant memory structures accordingly.

5. On the segment node side: in the main loop of PostgresMain(), we process
   the requests from the master FTS probe process. ProcessStartupPacket() is
   called first to make sure this dialog is for FTS requests and thus the
   Postgres process spawn for it would be a FTS handler(am_ftshandler = true).
   Then it accepts the request and process the ‘Q’ type message using
   HandleFtsMessage(). This function deals with three kinds of requests:

        - Probe
        - Sync
        - Promote

6. The FTS probe on master supposed to run forever, but a SIGUSR2 signal may
   terminate it. Not sure how this can happen, my understanding is this might
   be used for debug purpose.

   After the changes done in PR 7364, SIGUSR2 is no longer used in the FTS
   probe service. So it is gone.


