
Fault Tolerance Service (FTS)
================================

This document illustrates the mechanism of a GPDB component called Fault
Tolerance Service (FTS):

1. The FTS probe process is running on the Gp_entry_postmaster (master
   node) only. It starts as a background worker process managed
   by the BackgroundWorker structure. (see src/include/postmaster/bgworker.h).
   Greenplum sets up a group of GP background processes through an
   array structure PMAuxProcList. There each entry is for one GP background
   process.

   The most important members of the BackgroundWorker structure are two
   function pointers. One is the pointer of the main entry function of the
   GP background process and the other one is the pointer of the function
   that determine if the process should be started. For FTS, the two
   pointers are FtsProbeMain() and FtsProbeStartRule(), respectively.
   This is hard-coded in postmaster.c.

         #define MaxPMAuxProc 6 
         static BackgroundWorker PMAuxProcList[MaxPMAuxProc]   ...

     In Postmaster, we will check the following condition:

        Gp_entry_postmaster && Gp_role == GP_ROLE_DISPATCH

   The FTS probe process is started when the condition is true.

   In the initialization phase, we register one BackgroundWorker entry
   for each GP background process into postmaster's private structure
   BackgroundWorkerList. When we do this, the above condition is checked
   to decide if FTS should be registered there or not. The reader may
   want to check load_auxiliary_libraries() for more detial.

   Later, the postmaster tries to start the processes that have been
   registered in the BackgroundWorkerList, which includes the FTS
   probe process. For the cases that the first attempt to start
   a particular process fails, or a process goes down for some reason
   and then needs to be brought up again, postmaster gets the chances
   to re-start it in its main loop. At a iteration, it checks
   the status of these processes and acts accordingly.

   This is how the FTS probe process is started.


2. The FTS probe process always runs in a infinite loop and trying to
   do one round of polling at each iteration to get the health status
   of all segments. At each iteration, it wait one a latch with timeout
   to block itself for a while. Thus, two types of events might
   trigger the polling. One is timeout on the latch it is waiting for,
   and the other one is that someone sets the latch.

   Certain components running on master node may interrupt FTS from its
   wait to trigger a probe immediately. This is referred to as notifying
   FTS. Dispatcher is one such component. As an example, it can notify
   FTS if it encounters an error while creating a gang. The reader may
   check FtsNotifyProber() to find more cases.

   This is the way how the FTS probe process starts a round of polling.

3. On the master node side, the FTS probe process gets the configuration
   from catelog table gp_segment_configuration, which describes the status
   of each segment and also tells if any of them has a mirror. In a simple
   case, we can think of that, for each unique content(or segindex) value,
   we may see a primary segment and a mirror segment. The two make a pair
   and they have the same content(or segindex) value but different dbid.

   FTS probes only the primary segments. Primary segments provide their own
   status as well as their mirror's status in response. When a primary segment
   is found to be down, FTS promotes its mirror, only if it was in-sync with
   the primary. If the mirror is out-of-sync, this is considered "double
   failure" and FTS does nothing. The cluster is unusable in this case.

   If FTS, upon probing segments, finds any change, it would update segment
   configuration. Dispatcher would then use the new configuration to create
   gangs.

   So FTS both read and write the catelog table.

4. On the master node side: each round of the polling is done in a chain of
   calls :

        ftsConnect()
        ftsPoll()
        ftsSend()
        ftsReceive()
        processRetry()
        processResponse().

   FTS probe process connects to each primary segment node(or mirror segment
   when failover occurs) through TCP/IP. It sends requests to segment and
   waits for the responses. Once a response is received, it updates the
   catalog table gp_segment_configuration and pg_configure_history, and also
   relevant memory structures accordingly.

5. On the segment node side: in the main loop of PostgresMain(), we process
   the requests from the master FTS probe process. ProcessStartupPacket() is
   called first to make sure this dialog is for FTS requests and thus the
   Postgres process spawn for it would be a FTS handler(am_ftshandler = true).
   Then it accepts the request and process the ‘Q’ type message using
   HandleFtsMessage(). This function deals with three kinds of requests:

        - Probe
        - Sync
        - Promote

6. SIGUSR2 is ignored by FTS now, like other background, postmaster use
   SIGTERM to stop the FTS.


