
Fault Tolerance Service (FTS)
================================

This document illustrates the mechanism of a GPDB component called Fault
Tolerance Service (FTS):

1. The FTS probe process is running on the Gp_entry_postmaster (master
   node) only. It starts as a background worker process managed
   by the BackgroundWorker structure. (see src/include/postmaster/bgworker.h).
   Greenplum sets up a group of GP background processes through an
   array structure PMAuxProcList. There each entry is for one GP background
   process.

   The most important members of the BackgroundWorker structure are two
   function pointers. One is the pointer of the main entry function of the
   GP background process and the other one is the pointer of the function
   that determine if the process should be started. For FTS, the two
   pointers are FtsProbeMain() and FtsProbeStartRule(), respectively.
   This is hard-coded in postmaster.c.

         #define MaxPMAuxProc 6 
         static BackgroundWorker PMAuxProcList[MaxPMAuxProc]   ...

     In Postmaster, we will check the following condition:

        Gp_entry_postmaster && Gp_role == GP_ROLE_DISPATCH

   The FTS probe process is started when the condition is true.

   In PostmasterMain(), the function load_auxiliary_libraries() is called
   to register one BackgroundWorker entry for each GP background process
   into postmaster's private structure BackgroundWorkerList. The above
   condition is checked to decide if FTS is registered there or not.

   Later in PostmasterMain(), maybe_start_bgworker() is called to start
   all the GP background processes in the BackgroundWorkerList,
   including FTS. This call is made outside of the ServerLoop() of
   postmaster at the first time. Later, it will also be called inside
   the ServerLoop() to handle other cases. For example, a backend process
   is down and postmaster needs to have a chance to bring it up again.

   This is how the FTS probe process is started.


2. The FTS probe process always runs in a infinite loop and trying to
   do one round of polling at each iteration to get the health status
   of all segments. At each iteration, it calls WaitLatch with timeout
   to block itself for a while. Thus, two types of events might actually
   trigger the polling actually. One is timeout on the latch, and the
   other one is that someone sets the latch.

   In many code running on the master node, e.g. inside the code of the
   function cdbgang_createGang_async(), if we hit the PG_CATCH block,
   FtsNotifyProber() is called to signal postmaster with SIGINT, and
   the postmaster’s SIGINT handler calls SetLatch() to unblock the FTS
   main loop if it is now waiting on the Latch.

   This is the way how the FTS probe process starts a round of polling.

3. On the master node side, the FTS probe process gets the configuration
   from catelog table pg_segement_configure, which describes the status of
   each segment and also tells if any of them has a mirror. In a simple
   case, we can think of that, for each unique content(or segindex) value,
   we may see a primary segment and a mirror segment. The two make a pair
   and they have the same content(or segindex) value but different dbid.
   The FTS’s job is to periodically (sometimes event driven) poll all the
   segments that have mirror setup. If any of them is in down status, FTS
   promotes the mirror to be the primary (swap them). In summary, The FTS
   probe gets the needed information of all segments from these catalog
   tables and also update them according to the dynamically changing
   runtime status.

4. On the master node side: each round of the polling is done in a chain of
   calls :

        ftsConnect()
        ftsPoll()
        ftsSend()
        ftsReceive()
        processRetry()
        processResponse().

   FTS probe process connects to each primary segment node(or mirror segment
   when failover occurs) through TCP/IP. It sends requests to segment and
   waits for the responses. Once a response is received, it updates the
   catalog table pg_segement_configure and pg_configure_history, and also
   relevant memory structures accordingly.

5. On the segment node side: in the main loop of PostgresMain(), we process
   the requests from the master FTS probe process. ProcessStartupPacket() is
   called first to make sure this dialog is for FTS requests and thus the
   Postgres process spawn for it would be a FTS handler(am_ftshandler = true).
   Then it accepts the request and process the ‘Q’ type message using
   HandleFtsMessage(). This function deals with three kinds of requests:

        - Probe
        - Sync
        - Promote

6. Not sure if FTS can be stopped by SIGUSR2 now.


